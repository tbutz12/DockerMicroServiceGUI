version: "3.9"  # optional since v1.27.0
services:
  gui:
    build:
      context: ./java
      dockerfile: ./Dockerfile
    container_name: gui
    environment:
      - DISPLAY=192.168.1.162:0.0
  tensorflow-server:
    image: "asap397/my-tensorflow-server"
    environment:
      - MODEL_NAME=half_plus_two
    ports:
      - 8501:8501
    container_name: tensorflow-server
  tensorflowp:
    build:
      context: ./tensorflow
    environment:
      - DISPLAY=192.168.1.162:0.0
    ports:
      - 6002:6002
    container_name: tensorflow_listener
  rstudio:
    image: "rocker/rstudio"
    ports:
      - 8787:8787
    environment:
      - DISABLE_AUTH=true
    container_name: rstudio
  jupyter:
    image: jupyter/minimal-notebook
    ports:
      - 8888:8888
    environment:
      - JUPYTER_TOKEN=easy
    container_name: jupyter
  markdown:
    image: "v4tech/markdown-editor"
    ports:
      - 12345:80
    container_name: "markdown"
  vs:
    image: ghcr.io/linuxserver/code-server
    container_name: code-server
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Europe/London
    volumes:
      - /path/to/appdata/config:/config
    ports:
      - 8443:8443
    restart: unless-stopped
    container_name: vs
  sonarqube:
    image: sonarqube
    ports:
      - 9001:9000
      - 9092:9092
    environment:
      - SONAR_ES_BOOTSTRAP_CHECKS_DISABLE=true
    container_name: sonarqube
    logging:
      driver: none
  spyder:
    build:
      context: ./spyder
    container_name: spyder
    container_name: spyder
    environment:
      - DISPLAY=192.168.1.162:0.0
    ports:
      - 6004:6004
  orange:
    image: "tmb132/orange"
    container_name: orange
    environment:
      - DISPLAY=192.168.1.162:0.0
    ports:
      - 6008:6008
  git:
    image: "tmb132/git"
    container_name: git
    environment:
      - DISPLAY=192.168.1.162:0.0
    ports:
      - 6006:6006
  spark-master:
    image: "sdesilva26/spark_master:0.0.2"
    container_name: spark-master
    networks:
      - spark-net
    ports:
      - 8080:8080
  spark-worker:
    image: "sdesilva26/spark_worker:0.0.2"
    container_name: spark-worker
    networks:
      - spark-net
    ports:
      - 8081:8081
    environment:
      - MEMORY=2G
      - CORES=1
    depends_on:
      - spark-master
  spark-worker2:
    image: "sdesilva26/spark_worker:0.0.2"
    container_name: spark-worker2
    networks:
      - spark-net
    ports:
      - 8082:8081
    environment:
      - MEMORY=2G
      - CORES=1
    depends_on:
      - spark-worker
  spark-submit:
    image: "sdesilva26/spark_submit"
    container_name: spark-submit
    networks:
      - spark-net
    ports:
      - 4040:4040
    environment:
      - MEMORY=2G
      - CORES=1
    stdin_open: true # docker run -i
    tty: true        # docker run -t
  sas:
    build:
      context: ./sas
    container_name: sas
    ports:
      - 3002:3002
    environment:
      - DISPLAY=192.168.1.162:0.0
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: always
    ports:
      - 9870:9870
      - 9000:9000
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env
  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    restart: always
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env
  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864"
    env_file:
      - ./hadoop.env
  nodemanager1:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    env_file:
      - ./hadoop.env
  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: historyserver
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop.env
volumes:
  hadoop_namenode:
  hadoop_datanode:
  hadoop_historyserver:


networks:
  default:
  spark-net:
    driver: spark-net
