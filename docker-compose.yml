version: '3.9'  # optional since v1.27.0
services:
  gui:
    image: "tmb132/java"
    container_name: gui
    env_file:
      - ./.env
    depends_on:
      - rstudio
      - spyder
      - git
      - spark
      - markdown
      - vs
      - tensorflow
      - sas
      - namenode_run
      - orange
  rstudio:
    image: "rocker/rstudio"
    ports:
      - 8787:8787
    environment:
      - DISABLE_AUTH=true
    container_name: rstudio
  jupyter:
    image: jupyter/minimal-notebook
    ports:
      - 8888:8888
    environment:
      - JUPYTER_TOKEN=easy
    container_name: jupyter
  markdown:
    image: "v4tech/markdown-editor"
    ports:
      - 12345:80
    container_name: "markdown"
  vs:
    image: ghcr.io/linuxserver/code-server
    container_name: code-server
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Europe/London
    volumes:
      - /path/to/appdata/config:/config
    ports:
      - 8443:8443
    restart: unless-stopped
    container_name: vs
  sonarqube:
    image: sonarqube
    ports:
      - 9001:9000
      - 9092:9092
    environment:
      - SONAR_ES_BOOTSTRAP_CHECKS_DISABLE=true
    container_name: sonarqube
    logging:
      driver: none
  spyder:
    image: "tmb132/spyder-app"
    container_name: spyder
    env_file:
      - ./.env
    ports:
      - 6004:6004
  orange:
    image: "tmb132/orange"
    container_name: orange
    env_file:
      - ./.env
    ports:
      - 6008:6008
  git:
    image: "tmb132/git"
    container_name: git
    env_file:
      - ./.env
    ports:
      - 6006:6006
  sas:
    image: "tmb132/sas"
    container_name: sas
    ports:
      - 3002:3002
    env_file:
      - ./.env
  namenode:
    image: "tmb132/hadooprun"
    container_name: namenode
    restart: always
    ports:
      - 9870:9870
      - 9000:9000
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
      - /input:/input
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env
  namenode_run:
    image: "tmb132/namenoderun"
    container_name: namenode_run
    env_file:
      - ./.env
    ports:
      - 3004:3004
    privileged: true
    volumes:
        - /var/run/docker.sock:/var/run/docker.sock
  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    restart: always
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env
  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864"
    env_file:
      - ./hadoop.env
  nodemanager1:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    env_file:
      - ./hadoop.env
  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: historyserver
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop.env
  spark:
    image: "tmb132/spark"
    container_name: spark
    env_file:
      - ./.env
    ports:
      - 3006:3006
  tensorflow:
    image: "tmb132/tensorflow"
    container_name: tensorflow
    env_file:
      - ./.env
    ports:
      - 6002:6002
    privileged: true
    volumes:
        - /var/run/docker.sock:/var/run/docker.sock

volumes:
  hadoop_namenode:
  hadoop_datanode:
  hadoop_historyserver:
